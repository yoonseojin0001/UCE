{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"CompVis/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"artists_sd.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = [t.strip() for t in re.split(\"[,\\n]+\", text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "artists = list(pd.read_csv(\"all_artists_prompts.csv\")[\"artist\"].unique())\n",
    "with open(\"artists.yaml\", \"w\") as file:\n",
    "    yaml.dump(artists, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aaron Douglas', 'actor ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[1].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "with open(f\"artists.yaml\", 'r', encoding='utf-8') as file:\n",
    "    artists = yaml.safe_load(file)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model32, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model14, preprocess = clip.load(\"ViT-L/14\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.8 32.6 32.0 27.6 27.6 26.1 \n",
      "33.1 29.3 28.8 25.3 25.2 23.2 \n",
      "34.9 32.1 30.3 28.1 28.3 25.2 \n",
      "31.0 31.5 29.5 25.4 25.4 23.4 \n",
      "36.4 31.0 28.9 29.0 28.2 24.9 \n",
      "\n",
      "31.7 29.9 29.5 24.2 24.4 23.4 \n",
      "33.9 29.5 30.5 28.5 26.5 28.2 \n",
      "30.1 27.7 28.4 26.7 27.5 26.0 \n",
      "30.3 28.0 28.5 25.5 23.1 24.8 \n",
      "25.2 26.4 23.8 23.3 25.0 24.2 \n",
      "\n",
      "26.1 28.7 27.1 24.0 21.0 22.9 \n",
      "28.7 27.9 25.9 23.3 21.7 24.7 \n",
      "26.4 26.9 25.5 25.3 24.2 24.3 \n",
      "25.8 26.3 27.4 25.0 19.7 22.8 \n",
      "24.4 26.7 26.5 24.5 20.7 23.8 \n",
      "\n",
      "29.4 28.9 29.7 25.7 25.4 26.6 \n",
      "29.6 30.8 32.7 26.7 24.7 26.1 \n",
      "26.9 27.2 28.5 23.2 21.8 23.5 \n",
      "27.2 27.3 30.5 24.9 20.2 24.5 \n",
      "28.4 26.5 27.9 20.7 18.2 23.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in artists[:4]:\n",
    "    text = clip.tokenize([f\"{artist}\", f\"An image in the style of {artist}\", f\"An image depicting {artist}\"]).to(device)\n",
    "    for index in range(5):\n",
    "        image = preprocess(Image.open(f\"{artist}/{index}.jpg\")).unsqueeze(0).to(device)\n",
    "\n",
    "        scores, _ = model32(image, text)\n",
    "        for score in scores[0]:\n",
    "            print(f\"{score:.1f}\", end=\" \")\n",
    "\n",
    "        scores, _ = model14(image, text)\n",
    "        for score in scores[0]:\n",
    "            print(f\"{score:.1f}\", end=\" \")\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A.J.Casson\n",
      "0 A.J.Casson\n",
      "0 A.J.Casson\n",
      "1 Lawren Harris\n",
      "0 A.J.Casson\n",
      "\n",
      "0 Aaron Douglas\n",
      "0 Aaron Douglas\n",
      "0 Aaron Douglas\n",
      "2 Tom Hammick\n",
      "12 Peter Mohrbacher\n",
      "\n",
      "13 Jim Woodring\n",
      "0 Aaron Horkey\n",
      "1 John Blanche\n",
      "36 Leonora Carrington\n",
      "99 Masaaki Sasamoto\n",
      "\n",
      "0 Aaron Jasinski\n",
      "0 Aaron Jasinski\n",
      "6 Esao Andrews\n",
      "10 Adrian Smith\n",
      "5 Lori Earley\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "with open(f\"artists.yaml\", 'r', encoding='utf-8') as file:\n",
    "    artists = yaml.safe_load(file)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "text = clip.tokenize(artists).to(device)\n",
    "for i, artist in enumerate(artists[:4]):\n",
    "    for index in range(5):\n",
    "        image = preprocess(Image.open(f\"{artist}/{index}.jpg\")).unsqueeze(0).to(device)\n",
    "        scores = model(image, text)[0][0]\n",
    "        print((torch.argsort(scores, descending=True) == i).nonzero().item(), end=\" \")\n",
    "        print(artists[torch.max(scores, 0)[1].item()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.1797, 16.4062, 21.3906,  ..., 19.2969, 16.2031, 19.7344],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model(image, text)[0][0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1205,  427,  167,  ...,  767,  529, 1777], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(scores, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = artists[0]\n",
    "index = 0\n",
    "image = preprocess(Image.open(f\"{artist}/{index}.jpg\")).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.J.Casson\n",
      "A.J.Casson\n",
      "A.J.Casson\n",
      "Lawren Harris\n",
      "A.J.Casson\n"
     ]
    }
   ],
   "source": [
    "artist = artists[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
